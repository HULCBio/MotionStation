% TREEFIT   分類または回帰に対する樹形モデルの近似
%
% T = TREEFIT(X,Y) は、予測変数 X の関数として応答 Y を予測するために
% 決定木 T を作成します。X は、予測子の N×M 行列です。Y は、(回帰に
% 対する) N の応答値のベクトルか、または、(分類に対する) N の分類名を
% 含む文字列の文字配列かセル配列のどちらかです。どちらにせよ、T は、
% X の列の値に基づいて個々の終端ではないノードから分岐していく二進木です。
%
% T = TREEFIT(X,Y,'PARAM1',val1,'PARAM2',val2,...) は、オプションの
% パラメータ 名/値 の組を指定します。:
%
% すべてのツリーに対して:
%    'catidx'     X を並べられていないカテゴリ変数として取り扱うための
%                 X の列のインデックスベクトルです。
%    'method'     'classification' (Y がテキストの場合、デフォルトです)
%                 または、'regression' (Y が数値の場合、デフォルトです)
%    'splitmin'   数 N。不純物を含むノードは、N 個か、あるいは分割の
%                 ためのより多くの観測をもたなければなりません。
%                 (デフォルトは 10 です)
%    'prune'      完全なツリーとサブツリーを削除する最適手順を計算する
%                 には'on' (デフォルト) で、サブツリーは削除せず完全な
%                 ツリーだけ求める場合は'off'
%
% 分類木のみに対して:
%    'cost'       正方行列 C。C(i,j) は、真のクラスが j である点をクラ
%                 ス i に分類した場合のコストです。(i~=j の場合、デフォ
%                 ルトで C(i,j)=1 で、i=j の場合、C(i,j)=0 です)。ある
%                 いは、この値は2つのフィールドをもつ構造体 S に置き
%                 換えることもできます。: S.group は、文字の文字配列
%                 またはセル配列としてグループ名を含み、S.cost は、
%                 コスト行列 C を含みます。
%    'splitcriterion'  分割方法を決める基準。Gini の相違点インデックス
%                 に対する 'gdi' (デフォルト)か、twoing 規則に対する
%                 'twoing'、または、尤離度を最も減少させる 'deviance' 
%                 のいずれかになります。
%    'priorprob'  (個々の異なったグループ名に対して1つの値となる)ベクトル
%                 か、または2つのフィールドをもつ構造体 S として指定された、
%                 各分類に対する事前確率。フィールドはつぎの通りです。: 
%                 S.group は、文字の文字配列かセル配列としてグループ名を
%                 含み、S.prob は、対応する確率のベクトルを含んでいます。
%
% 例題:  Fisher の iris data に対する分類木を作成します。
%    load fisheriris;
%    t = treefit(meas, species);
%    treedisp(t,'names',{'SL' 'SW' 'PL' 'PW'});
%
% 参考 : TREEDISP, TREEPRUNE, TREETEST, TREEVAL.


%   Copyright 1993-2002 The MathWorks, Inc. 
%   $Revision: 1.6 $  $Date: 2002/05/09 18:27:30 $
