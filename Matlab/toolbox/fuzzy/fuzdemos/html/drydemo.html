<!--
This HTML is auto-generated from an m-file.
Your changes will be overwritten.
--><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium;">Overview</p><ul xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd"><li><a href="#Nonlinear system identification">Nonlinear system identification</a></li></ul><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;">Nonlinear system identification<a name="Nonlinear system identification"></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">This demo addresses the use of ANFIS function in the Fuzzy Logic
Toolbox for nonlinear dynamical system identification. This demo also
requires the System Identification Toolbox, as a comparison is made
between a nonlinear ANFIS and a linear ARX model.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Copyright 1994-2002 The MathWorks, Inc.
$Revision: 1.9 $
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px"><span style="color:green">% Exit if the IDENT toolbox is not on the path</span>
<span style="color:blue">if</span> exist(<span style="color:#B20000">'arx.m'</span>,<span style="color:#B20000">'file'</span>) == 0
  errordlg(<span style="color:#B20000">'DRYDEMO requires the System Identification Toolbox.'</span>);
  <span style="color:blue">return</span>;
<span style="color:blue">end</span></pre><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">The data set for ANFIS and ARX modeling was obtained from a laboratory
device called Feedback's Process Trainer PT 326, as described in Chapter
17 of Prof. Lennart Ljung's book "System Identification, Theory for the
User", Prentice-Hall, 1987. The device's function is like a hair dryer:
air is fanned through a tube and heated at the inlet. The air temperature
is measure by a thermocouple at the outlet. The input u(k) is the voltage
over a mesh of resistor wires to heat incoming air; the output y(k) is
the outlet air temperature. Here is a the system model
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">a=imread(<span style="color:#B20000">'dryblock.jpg'</span>, <span style="color:#B20000">'jpg'</span>);
image(a); 
axis image;
axis off;</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="drydemo_img02.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Here are the results of the test.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">load dryer2;
data_n = length(y2);
output = y2;
input = [[0; y2(1:data_n-1)] <span style="color:blue">...</span>
        [0; 0; y2(1:data_n-2)] <span style="color:blue">...</span>
        [0; 0; 0; y2(1:data_n-3)] <span style="color:blue">...</span>
        [0; 0; 0; 0; y2(1:data_n-4)] <span style="color:blue">...</span>
        [0; u2(1:data_n-1)] <span style="color:blue">...</span>
        [0; 0; u2(1:data_n-2)] <span style="color:blue">...</span>
        [0; 0; 0; u2(1:data_n-3)] <span style="color:blue">...</span>
        [0; 0; 0; 0; u2(1:data_n-4)] <span style="color:blue">...</span>
        [0; 0; 0; 0; 0; u2(1:data_n-5)] <span style="color:blue">...</span>
        [0; 0; 0; 0; 0; 0; u2(1:data_n-6)]];
data = [input output];
data(1:6, :) = [];
input_name = str2mat(<span style="color:#B20000">'y(k-1)'</span>,<span style="color:#B20000">'y(k-2)'</span>,<span style="color:#B20000">'y(k-3)'</span>,<span style="color:#B20000">'y(k-4)'</span>,<span style="color:#B20000">'u(k-1)'</span>,<span style="color:#B20000">'u(k-2)'</span>,<span style="color:#B20000">'u(k-3)'</span>,<span style="color:#B20000">'u(k-4)'</span>,<span style="color:#B20000">'u(k-5)'</span>,<span style="color:#B20000">'u(k-6)'</span>);
trn_data_n = 300;
index = 1:100;
subplot(2,1,1);
plot(index, y2(index), <span style="color:#B20000">'-'</span>, index, y2(index), <span style="color:#B20000">'o'</span>);
ylabel(<span style="color:#B20000">'y(k)'</span>);
subplot(2,1,2);
plot(index, u2(index), <span style="color:#B20000">'-'</span>, index, u2(index), <span style="color:#B20000">'o'</span>);
ylabel(<span style="color:#B20000">'u(k)'</span>);</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="drydemo_img03.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">The data points was collected at a sampling time of 0.08 second. One
thousand input-output data points were collected from the process as the
input u(k) was chosen to be a binary random signal shifting between 3.41
and 6.41 V. The probability of shifting the input at each sample was 0.2.
The data set is available from the System Identification Toolbox; and the
above plots show the output temperature y(k) and input voltage u(t) for
the first 100 time steps.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">A conventional method is to remove the means from the data and assume a
linear model of the form:
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">y(k)+a1*y(k-1)+...+am*y(k-m)=b1*u(k-d)+...+bn*u(k-d-n+1)
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">where ai (i = 1 to m) and bj (j = 1 to n) are linear parameters to be
determined by least-squares methods. This structure is called the ARX
model and it is exactly specified by three integers [m, n, d]. To find an
ARX model for the dryer device, the data set was divided into a training
(k = 1 to 300) and a checking (k = 301 to 600) set.  An exhaustive search
was performed to find the best combination of [m, n, d], where each of
the integer is allowed to changed from 1 to 10 independently. The best
ARX model thus found is specified by [m, n, d] = [5, 10, 2], with a
training RMSE of 0.1122 and a checking RMSE of 0.0749. The above figure
demonstrates the fitting results of the best ARX model.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">trn_data_n = 300;
total_data_n = 600;
z = [y2 u2];
z = dtrend(z);
ave = mean(y2);
ze = z(1:trn_data_n, :);
zv = z(trn_data_n+1:total_data_n, :);
T = 0.08;

<span style="color:green">% Run through all different models</span>
V = arxstruc(ze, zv, struc(1:10, 1:10, 1:10));
<span style="color:green">% Find the best model</span>
nn = selstruc(V, 0);
<span style="color:green">% Time domain plot</span>
th = arx(ze, nn);
th = sett(th, 0.08);
u = z(:, 2);
y = z(:, 1)+ave;
yp = idsim(u, th)+ave;

xlbl = <span style="color:#B20000">'Time Steps'</span>;

subplot(2,1,1); 
index = 1:trn_data_n;
plot(index, y(index), index, yp(index), <span style="color:#B20000">'.'</span>);
rmse = norm(y(index)-yp(index))/sqrt(length(index));
title([<span style="color:#B20000">'(a) Training Data (Solid Line) and ARX Prediction (Dots) with RMSE = '</span> num2str(rmse)]);
disp([<span style="color:#B20000">'[na nb d] = '</span> num2str(nn)]);
xlabel(xlbl);

subplot(2,1,2); 
index = (trn_data_n+1):(total_data_n);
plot(index, y(index), index, yp(index), <span style="color:#B20000">'.'</span>);
rmse = norm(y(index)-yp(index))/sqrt(length(index));
title([<span style="color:#B20000">'(b) Checking Data (Solid Line) and ARX Prediction (Dots) with RMSE = '</span> num2str(rmse)]);
xlabel(xlbl);</pre><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:gray; font-style:italic;">[na nb d] = 5 10  2
</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="drydemo_img05.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">The ARX model is inherently linear and the most significant advantage is
that we can perform model structure and parameter identification rapidly.
The performance in the above plots appear to be satisfactory. However, if
a better performance level is desired, we might want to resort to a
nonlinear model.  In particular, we are going to use a neuro-fuzzy
modeling approach, ANFIS, to see if we can push the performance level by
using a fuzzy inference system.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">To use ANFIS for system identification, the first thing we need to do is
input selection. That is, to determine which variables should be the
input arguments to an ANFIS model.  For simplicity, we suppose that there
are 10 input candidates (y(k-1), y(k-2), y(k-3), y(k-4), u(k-1), u(k-2),
u(k-3), u(k-4), u(k-5), u(k-6)), and the output to be predicted is y(k).
A heuristic approach to input selection is called sequential forward
search, in which each input is selected sequentially to optimize the
total squared error. This can be done by the function seqsrch; the result
is shown in the above plot, where 3 inputs (y(k-1), u(k-3), and u(k-4))
are selected with a training RMSE of 0.0609 and checking RMSE of 0.0604.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">trn_data_n = 300;
trn_data = data(1:trn_data_n, :);
chk_data = data(trn_data_n+1:trn_data_n+300, :);
[input_index, elapsed_time]=seqsrch(3, trn_data, chk_data, input_name);
fprintf(<span style="color:#B20000">'\nElapsed time = %f\n'</span>, elapsed_time);
winH1 = gcf;</pre><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:gray; font-style:italic;">
Selecting input 1 ...
ANFIS model 1: y(k-1) --&gt; trn=0.2043, chk=0.1888
ANFIS model 2: y(k-2) --&gt; trn=0.3819, chk=0.3541
ANFIS model 3: y(k-3) --&gt; trn=0.5245, chk=0.4903
ANFIS model 4: y(k-4) --&gt; trn=0.6308, chk=0.5977
ANFIS model 5: u(k-1) --&gt; trn=0.8271, chk=0.8434
ANFIS model 6: u(k-2) --&gt; trn=0.7976, chk=0.8087
ANFIS model 7: u(k-3) --&gt; trn=0.7266, chk=0.7349
ANFIS model 8: u(k-4) --&gt; trn=0.6215, chk=0.6346
ANFIS model 9: u(k-5) --&gt; trn=0.5419, chk=0.5650
ANFIS model 10: u(k-6) --&gt; trn=0.5304, chk=0.5601
Currently selected inputs: y(k-1)

Selecting input 2 ...
ANFIS model 11: y(k-1) y(k-2) --&gt; trn=0.1085, chk=0.1024
ANFIS model 12: y(k-1) y(k-3) --&gt; trn=0.1339, chk=0.1283
ANFIS model 13: y(k-1) y(k-4) --&gt; trn=0.1542, chk=0.1461
ANFIS model 14: y(k-1) u(k-1) --&gt; trn=0.1892, chk=0.1734
ANFIS model 15: y(k-1) u(k-2) --&gt; trn=0.1663, chk=0.1574
ANFIS model 16: y(k-1) u(k-3) --&gt; trn=0.1082, chk=0.1077
ANFIS model 17: y(k-1) u(k-4) --&gt; trn=0.0925, chk=0.0948
ANFIS model 18: y(k-1) u(k-5) --&gt; trn=0.1533, chk=0.1531
ANFIS model 19: y(k-1) u(k-6) --&gt; trn=0.1952, chk=0.1853
Currently selected inputs: y(k-1) u(k-4)

Selecting input 3 ...
ANFIS model 20: y(k-1) u(k-4) y(k-2) --&gt; trn=0.0808, chk=0.0822
ANFIS model 21: y(k-1) u(k-4) y(k-3) --&gt; trn=0.0806, chk=0.0836
ANFIS model 22: y(k-1) u(k-4) y(k-4) --&gt; trn=0.0817, chk=0.0855
ANFIS model 23: y(k-1) u(k-4) u(k-1) --&gt; trn=0.0886, chk=0.0912
ANFIS model 24: y(k-1) u(k-4) u(k-2) --&gt; trn=0.0835, chk=0.0843
ANFIS model 25: y(k-1) u(k-4) u(k-3) --&gt; trn=0.0609, chk=0.0604
ANFIS model 26: y(k-1) u(k-4) u(k-5) --&gt; trn=0.0848, chk=0.0867
ANFIS model 27: y(k-1) u(k-4) u(k-6) --&gt; trn=0.0890, chk=0.0894
Currently selected inputs: y(k-1) u(k-3) u(k-4)

Elapsed time = 1.091000
</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="drydemo_img07.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">For input selection, another more computation intensive approach is to do
an exhaustive search on all possible combinations of the input
candidates. The function that performs exhaustive search is exhsrch,
which selects 3 inputs from 10 candidates.  However, exhsrch usually
involves a significant amount of computation if all combinations are
tried.  For instance, if 3 is selected out of 10, the total number of
ANFIS models is C(10, 3) = 120.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Fortunately, for dynamical system identification, we do know that the inputs should not come from either of the following two sets of input candidates exclusively:
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Y = {y(k-1), y(k-2), y(k-3), y(k-4)}
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">U = {u(k-1), u(k-2), u(k-3), u(k-4), u(k-5), u(k-6)}
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">A reasonable guess would be to take two inputs from Y and one from U to
form the inputs to ANFIS; the total number of ANFIS models is then
C(4,2)*6=36, which is much less.  The above plot shows that the selected
inputs are y(k-1), y(k-2) and u(k-3), with a training RMSE of 0.0474 and
checking RMSE of 0.0485, which are better than ARX models and ANFIS via
sequential forward search.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">group1 = [1 2 3 4];	<span style="color:green">% y(k-1), y(k-2), y(k-3), y(k-4)</span>
group2 = [1 2 3 4];	<span style="color:green">% y(k-1), y(k-2), y(k-3), y(k-4)</span>
group3 = [5 6 7 8 9 10];	<span style="color:green">% u(k-1) through y(k-6)</span>

anfis_n = 6*length(group3);
index = zeros(anfis_n, 3);
trn_error = zeros(anfis_n, 1);
chk_error = zeros(anfis_n, 1);
<span style="color:green">% ======= Training options </span>
mf_n = 2;
mf_type = <span style="color:#B20000">'gbellmf'</span>;
epoch_n = 1;
ss = 0.1;
ss_dec_rate = 0.5;
ss_inc_rate = 1.5;
<span style="color:green">% ====== Train ANFIS with different input variables</span>
fprintf(<span style="color:#B20000">'\nTrain %d ANFIS models, each with 3 inputs selected from 10 candidates...\n\n'</span>,<span style="color:blue">...</span>
    anfis_n);
model = 1;
<span style="color:blue">for</span> i=1:length(group1),
    <span style="color:blue">for</span> j=i+1:length(group2),
        <span style="color:blue">for</span> k=1:length(group3),
            in1 = deblank(input_name(group1(i), :));
            in2 = deblank(input_name(group2(j), :));
            in3 = deblank(input_name(group3(k), :));
            index(model, :) = [group1(i) group2(j) group3(k)];
            trn_data = data(1:trn_data_n, [group1(i) group2(j) group3(k) size(data,2)]);
            chk_data = data(trn_data_n+1:trn_data_n+300, [group1(i) group2(j) group3(k) size(data,2)]);
            in_fismat = genfis1(trn_data, mf_n, mf_type);
            [trn_out_fismat t_err step_size chk_out_fismat c_err] = <span style="color:blue">...</span>
                anfis(trn_data, in_fismat, <span style="color:blue">...</span>
                [epoch_n nan ss ss_dec_rate ss_inc_rate], <span style="color:blue">...</span>
                [0 0 0 0], chk_data, 1);
            trn_error(model) = min(t_err);
            chk_error(model) = min(c_err);
            fprintf(<span style="color:#B20000">'ANFIS model = %d: %s %s %s'</span>, model, in1, in2, in3);
            fprintf(<span style="color:#B20000">' --&gt; trn=%.4f,'</span>, trn_error(model));
            fprintf(<span style="color:#B20000">' chk=%.4f'</span>, chk_error(model));
            fprintf(<span style="color:#B20000">'\n'</span>);
            model = model+1;
        <span style="color:blue">end</span>
    <span style="color:blue">end</span>
<span style="color:blue">end</span>

<span style="color:green">% ====== Reordering according to training error</span>
[a b] = sort(trn_error);
b = flipud(b);		<span style="color:green">% List according to decreasing trn error</span>
trn_error = trn_error(b);
chk_error = chk_error(b);
index = index(b, :);

<span style="color:green">% ====== Display training and checking errors</span>
x = (1:anfis_n)';
subplot(2,1,1);
plot(x, trn_error, <span style="color:#B20000">'-'</span>, x, chk_error, <span style="color:#B20000">'-'</span>, <span style="color:blue">...</span>
    x, trn_error, <span style="color:#B20000">'o'</span>, x, chk_error, <span style="color:#B20000">'*'</span>);
tmp = x(:, ones(1, 3))';
X = tmp(:);
tmp = [zeros(anfis_n, 1) max(trn_error, chk_error) nan*ones(anfis_n, 1)]';
Y = tmp(:);
hold on; 
plot(X, Y, <span style="color:#B20000">'g'</span>); 
hold off;
axis([1 anfis_n -inf inf]);
set(gca, <span style="color:#B20000">'xticklabel'</span>, []);

<span style="color:green">% ====== Add text of input variables</span>
<span style="color:blue">for</span> k = 1:anfis_n,
    text(x(k), 0, <span style="color:blue">...</span>
        [input_name(index(k,1), :) <span style="color:#B20000">' '</span> <span style="color:blue">...</span>
            input_name(index(k,2), :) <span style="color:#B20000">' '</span> <span style="color:blue">...</span>
            input_name(index(k,3), :)]);
<span style="color:blue">end</span>
h = findobj(gcf, <span style="color:#B20000">'type'</span>, <span style="color:#B20000">'text'</span>);
set(h, <span style="color:#B20000">'rot'</span>, 90, <span style="color:#B20000">'fontsize'</span>, 11, <span style="color:#B20000">'hori'</span>, <span style="color:#B20000">'right'</span>);
drawnow

<span style="color:green">% ====== Generate input_index for bjtrain.m</span>
[a b] = min(trn_error);
input_index = index(b,:);
title(<span style="color:#B20000">'Training (Circles) and Checking (Asterisks) Errors'</span>);
ylabel(<span style="color:#B20000">'RMSE'</span>);</pre><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:gray; font-style:italic;">
Train 36 ANFIS models, each with 3 inputs selected from 10 candidates...

ANFIS model = 1: y(k-1) y(k-2) u(k-1) --&gt; trn=0.0990, chk=0.0962
ANFIS model = 2: y(k-1) y(k-2) u(k-2) --&gt; trn=0.0852, chk=0.0862
ANFIS model = 3: y(k-1) y(k-2) u(k-3) --&gt; trn=0.0474, chk=0.0485
ANFIS model = 4: y(k-1) y(k-2) u(k-4) --&gt; trn=0.0808, chk=0.0822
ANFIS model = 5: y(k-1) y(k-2) u(k-5) --&gt; trn=0.1023, chk=0.0991
ANFIS model = 6: y(k-1) y(k-2) u(k-6) --&gt; trn=0.1021, chk=0.0974
ANFIS model = 7: y(k-1) y(k-3) u(k-1) --&gt; trn=0.1231, chk=0.1206
ANFIS model = 8: y(k-1) y(k-3) u(k-2) --&gt; trn=0.1047, chk=0.1085
ANFIS model = 9: y(k-1) y(k-3) u(k-3) --&gt; trn=0.0587, chk=0.0626
ANFIS model = 10: y(k-1) y(k-3) u(k-4) --&gt; trn=0.0806, chk=0.0836
ANFIS model = 11: y(k-1) y(k-3) u(k-5) --&gt; trn=0.1261, chk=0.1311
ANFIS model = 12: y(k-1) y(k-3) u(k-6) --&gt; trn=0.1210, chk=0.1151
ANFIS model = 13: y(k-1) y(k-4) u(k-1) --&gt; trn=0.1420, chk=0.1353
ANFIS model = 14: y(k-1) y(k-4) u(k-2) --&gt; trn=0.1224, chk=0.1229
ANFIS model = 15: y(k-1) y(k-4) u(k-3) --&gt; trn=0.0700, chk=0.0765
ANFIS model = 16: y(k-1) y(k-4) u(k-4) --&gt; trn=0.0817, chk=0.0855
ANFIS model = 17: y(k-1) y(k-4) u(k-5) --&gt; trn=0.1337, chk=0.1405
ANFIS model = 18: y(k-1) y(k-4) u(k-6) --&gt; trn=0.1421, chk=0.1333
ANFIS model = 19: y(k-2) y(k-3) u(k-1) --&gt; trn=0.2393, chk=0.2264
ANFIS model = 20: y(k-2) y(k-3) u(k-2) --&gt; trn=0.2104, chk=0.2077
ANFIS model = 21: y(k-2) y(k-3) u(k-3) --&gt; trn=0.1452, chk=0.1497
ANFIS model = 22: y(k-2) y(k-3) u(k-4) --&gt; trn=0.0958, chk=0.1047
ANFIS model = 23: y(k-2) y(k-3) u(k-5) --&gt; trn=0.2048, chk=0.2135
ANFIS model = 24: y(k-2) y(k-3) u(k-6) --&gt; trn=0.2388, chk=0.2326
ANFIS model = 25: y(k-2) y(k-4) u(k-1) --&gt; trn=0.2756, chk=0.2574
ANFIS model = 26: y(k-2) y(k-4) u(k-2) --&gt; trn=0.2455, chk=0.2400
ANFIS model = 27: y(k-2) y(k-4) u(k-3) --&gt; trn=0.1726, chk=0.1797
ANFIS model = 28: y(k-2) y(k-4) u(k-4) --&gt; trn=0.1074, chk=0.1157
ANFIS model = 29: y(k-2) y(k-4) u(k-5) --&gt; trn=0.2061, chk=0.2133
ANFIS model = 30: y(k-2) y(k-4) u(k-6) --&gt; trn=0.2737, chk=0.2836
ANFIS model = 31: y(k-3) y(k-4) u(k-1) --&gt; trn=0.3842, chk=0.3605
ANFIS model = 32: y(k-3) y(k-4) u(k-2) --&gt; trn=0.3561, chk=0.3358
ANFIS model = 33: y(k-3) y(k-4) u(k-3) --&gt; trn=0.2719, chk=0.2714
ANFIS model = 34: y(k-3) y(k-4) u(k-4) --&gt; trn=0.1763, chk=0.1808
ANFIS model = 35: y(k-3) y(k-4) u(k-5) --&gt; trn=0.2132, chk=0.2240
ANFIS model = 36: y(k-3) y(k-4) u(k-6) --&gt; trn=0.3460, chk=0.3601
</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="drydemo_img08.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">The popped window shows ANFIS predictions on both training and checking
data sets.  Obviously the performance is better than those of the ARX
model.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px"><span style="color:blue">if</span> ishandle(winH1), delete(winH1); <span style="color:blue">end</span>

ss = 0.01;
ss_dec_rate = 0.5;
ss_inc_rate = 1.5;

trn_data = data(1:trn_data_n, [input_index, size(data,2)]);
chk_data = data(trn_data_n+1:600, [input_index, size(data,2)]);

<span style="color:green">% generate FIS matrix</span>
in_fismat = genfis1(trn_data);

[trn_out_fismat trn_error step_size chk_out_fismat chk_error] = <span style="color:blue">...</span>
    anfis(trn_data, in_fismat, [1 nan ss ss_dec_rate ss_inc_rate], <span style="color:blue">...</span>
    nan, chk_data, 1);

subplot(2,1,1);
index = 1:trn_data_n;
plot(index, y(index), index, yp(index), <span style="color:#B20000">'.'</span>);
rmse = norm(y(index)-yp(index))/sqrt(length(index));
title([<span style="color:#B20000">'(a) Training Data (Solid Line) and ARX Prediction (Dots) with RMSE = '</span> num2str(rmse)]);
disp([<span style="color:#B20000">'[na nb d] = '</span> num2str(nn)]);
xlabel(<span style="color:#B20000">'Time Steps'</span>);
subplot(2,1,2);
index = (trn_data_n+1):(total_data_n);
plot(index, y(index), index, yp(index), <span style="color:#B20000">'.'</span>);
rmse = norm(y(index)-yp(index))/sqrt(length(index));
title([<span style="color:#B20000">'(b) Checking Data (Solid Line) and ARX Prediction (Dots) with RMSE = '</span> num2str(rmse)]);
xlabel(<span style="color:#B20000">'Time Steps'</span>);</pre><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:gray; font-style:italic;">
ANFIS info: 
	Number of nodes: 34
	Number of linear parameters: 32
	Number of nonlinear parameters: 18
	Total number of parameters: 50
	Number of training data pairs: 300
	Number of checking data pairs: 300
	Number of fuzzy rules: 8


Start training ANFIS ...

   1 	 0.0474113 	 0.0485325

Designated epoch number reached --&gt; ANFIS training completed at epoch 1.

[na nb d] = 5 10  2
</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="drydemo_img09.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">y_hat = evalfis(data(1:600,input_index), chk_out_fismat);

subplot(2,1,1);
index = 1:trn_data_n;
plot(index, data(index, size(data,2)), <span style="color:#B20000">'-'</span>, <span style="color:blue">...</span>
    index, y_hat(index), <span style="color:#B20000">'.'</span>);
rmse = norm(y_hat(index)-data(index,size(data,2)))/sqrt(length(index));
title([<span style="color:#B20000">'Training Data (Solid Line) and ANFIS Prediction (Dots) with RMSE = '</span> num2str(rmse)]);
xlabel(<span style="color:#B20000">'Time Index'</span>); ylabel(<span style="color:#B20000">''</span>);

subplot(2,1,2);
index = trn_data_n+1:600;
plot(index, data(index, size(data,2)), <span style="color:#B20000">'-'</span>, index, y_hat(index), <span style="color:#B20000">'.'</span>);
rmse = norm(y_hat(index)-data(index,size(data,2)))/sqrt(length(index));
title([<span style="color:#B20000">'Checking Data (Solid Line) and ANFIS Prediction (Dots) with RMSE = '</span> num2str(rmse)]);
xlabel(<span style="color:#B20000">'Time Index'</span>); ylabel(<span style="color:#B20000">''</span>);</pre><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:gray; font-style:italic;">Warning: Some input values are outside of the specified input range.
</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="drydemo_img10.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">The above table is a comparison among various modeling approaches. The
ARX modeling spends the least amount of time to reach the worse
precision, which the ANFIS modeling via exhaustive search takes the
largest amount of time to reach the best percision.  In other words, if
fast modeling is the goal, then ARX is the right choice.  But if
precision is the utmost concern, then we can go for ANFIS that is
designed for nonlinear modeling and higher precision.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">subplot(1,1,1)
a=imread(<span style="color:#B20000">'drytable.jpg'</span>, <span style="color:#B20000">'jpg'</span>);
image(a); 
axis image;
axis off;</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="drydemo_img11.gif"><originalCode xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" code="%% Nonlinear system identification&#xA;% This demo addresses the use of ANFIS function in the Fuzzy Logic&#xA;% Toolbox for nonlinear dynamical system identification. This demo also&#xA;% requires the System Identification Toolbox, as a comparison is made&#xA;% between a nonlinear ANFIS and a linear ARX model.&#xA;%&#xA;% Copyright 1994-2002 The MathWorks, Inc. &#xA;% $Revision: 1.9 $&#xA;&#xA;% Exit if the IDENT toolbox is not on the path&#xA;if exist('arx.m','file') == 0&#xA;  errordlg('DRYDEMO requires the System Identification Toolbox.');&#xA;  return;&#xA;end&#xA;&#xA;&#xA;%%&#xA;% The data set for ANFIS and ARX modeling was obtained from a laboratory&#xA;% device called Feedback's Process Trainer PT 326, as described in Chapter&#xA;% 17 of Prof. Lennart Ljung's book &#34;System Identification, Theory for the&#xA;% User&#34;, Prentice-Hall, 1987. The device's function is like a hair dryer:&#xA;% air is fanned through a tube and heated at the inlet. The air temperature&#xA;% is measure by a thermocouple at the outlet. The input u(k) is the voltage&#xA;% over a mesh of resistor wires to heat incoming air; the output y(k) is&#xA;% the outlet air temperature. Here is a the system model&#xA;&#xA;a=imread('dryblock.jpg', 'jpg');&#xA;image(a); &#xA;axis image;&#xA;axis off;&#xA;&#xA;%%&#xA;% Here are the results of the test.&#xA;&#xA;load dryer2;&#xA;data_n = length(y2);&#xA;output = y2;&#xA;input = [[0; y2(1:data_n-1)] ...&#xA;        [0; 0; y2(1:data_n-2)] ...&#xA;        [0; 0; 0; y2(1:data_n-3)] ...&#xA;        [0; 0; 0; 0; y2(1:data_n-4)] ...&#xA;        [0; u2(1:data_n-1)] ...&#xA;        [0; 0; u2(1:data_n-2)] ...&#xA;        [0; 0; 0; u2(1:data_n-3)] ...&#xA;        [0; 0; 0; 0; u2(1:data_n-4)] ...&#xA;        [0; 0; 0; 0; 0; u2(1:data_n-5)] ...&#xA;        [0; 0; 0; 0; 0; 0; u2(1:data_n-6)]];&#xA;data = [input output];&#xA;data(1:6, :) = [];&#xA;input_name = str2mat('y(k-1)','y(k-2)','y(k-3)','y(k-4)','u(k-1)','u(k-2)','u(k-3)','u(k-4)','u(k-5)','u(k-6)');&#xA;trn_data_n = 300;&#xA;index = 1:100;&#xA;subplot(2,1,1);&#xA;plot(index, y2(index), '-', index, y2(index), 'o');&#xA;ylabel('y(k)');&#xA;subplot(2,1,2);&#xA;plot(index, u2(index), '-', index, u2(index), 'o');&#xA;ylabel('u(k)');&#xA;&#xA;%%&#xA;% The data points was collected at a sampling time of 0.08 second. One&#xA;% thousand input-output data points were collected from the process as the&#xA;% input u(k) was chosen to be a binary random signal shifting between 3.41&#xA;% and 6.41 V. The probability of shifting the input at each sample was 0.2.&#xA;% The data set is available from the System Identification Toolbox; and the&#xA;% above plots show the output temperature y(k) and input voltage u(t) for&#xA;% the first 100 time steps.&#xA;&#xA;%%&#xA;% A conventional method is to remove the means from the data and assume a&#xA;% linear model of the form:&#xA;%&#xA;% y(k)+a1*y(k-1)+...+am*y(k-m)=b1*u(k-d)+...+bn*u(k-d-n+1)&#xA;%&#xA;% where ai (i = 1 to m) and bj (j = 1 to n) are linear parameters to be&#xA;% determined by least-squares methods. This structure is called the ARX&#xA;% model and it is exactly specified by three integers [m, n, d]. To find an&#xA;% ARX model for the dryer device, the data set was divided into a training&#xA;% (k = 1 to 300) and a checking (k = 301 to 600) set.  An exhaustive search&#xA;% was performed to find the best combination of [m, n, d], where each of&#xA;% the integer is allowed to changed from 1 to 10 independently. The best&#xA;% ARX model thus found is specified by [m, n, d] = [5, 10, 2], with a&#xA;% training RMSE of 0.1122 and a checking RMSE of 0.0749. The above figure&#xA;% demonstrates the fitting results of the best ARX model.&#xA;&#xA;trn_data_n = 300;&#xA;total_data_n = 600;&#xA;z = [y2 u2];&#xA;z = dtrend(z);&#xA;ave = mean(y2);&#xA;ze = z(1:trn_data_n, :);&#xA;zv = z(trn_data_n+1:total_data_n, :);&#xA;T = 0.08;&#xA;&#xA;% Run through all different models&#xA;V = arxstruc(ze, zv, struc(1:10, 1:10, 1:10));&#xA;% Find the best model&#xA;nn = selstruc(V, 0);&#xA;% Time domain plot&#xA;th = arx(ze, nn);&#xA;th = sett(th, 0.08);&#xA;u = z(:, 2);&#xA;y = z(:, 1)+ave;&#xA;yp = idsim(u, th)+ave;&#xA;&#xA;xlbl = 'Time Steps';&#xA;&#xA;subplot(2,1,1); &#xA;index = 1:trn_data_n;&#xA;plot(index, y(index), index, yp(index), '.');&#xA;rmse = norm(y(index)-yp(index))/sqrt(length(index));&#xA;title(['(a) Training Data (Solid Line) and ARX Prediction (Dots) with RMSE = ' num2str(rmse)]);&#xA;disp(['[na nb d] = ' num2str(nn)]);&#xA;xlabel(xlbl);&#xA;&#xA;subplot(2,1,2); &#xA;index = (trn_data_n+1):(total_data_n);&#xA;plot(index, y(index), index, yp(index), '.');&#xA;rmse = norm(y(index)-yp(index))/sqrt(length(index));&#xA;title(['(b) Checking Data (Solid Line) and ARX Prediction (Dots) with RMSE = ' num2str(rmse)]);&#xA;xlabel(xlbl);&#xA;&#xA;%%&#xA;% The ARX model is inherently linear and the most significant advantage is&#xA;% that we can perform model structure and parameter identification rapidly.&#xA;% The performance in the above plots appear to be satisfactory. However, if&#xA;% a better performance level is desired, we might want to resort to a&#xA;% nonlinear model.  In particular, we are going to use a neuro-fuzzy&#xA;% modeling approach, ANFIS, to see if we can push the performance level by&#xA;% using a fuzzy inference system.&#xA;&#xA;%%&#xA;% To use ANFIS for system identification, the first thing we need to do is&#xA;% input selection. That is, to determine which variables should be the&#xA;% input arguments to an ANFIS model.  For simplicity, we suppose that there&#xA;% are 10 input candidates (y(k-1), y(k-2), y(k-3), y(k-4), u(k-1), u(k-2),&#xA;% u(k-3), u(k-4), u(k-5), u(k-6)), and the output to be predicted is y(k).&#xA;% A heuristic approach to input selection is called sequential forward&#xA;% search, in which each input is selected sequentially to optimize the&#xA;% total squared error. This can be done by the function seqsrch; the result&#xA;% is shown in the above plot, where 3 inputs (y(k-1), u(k-3), and u(k-4))&#xA;% are selected with a training RMSE of 0.0609 and checking RMSE of 0.0604.&#xA;&#xA;trn_data_n = 300;&#xA;trn_data = data(1:trn_data_n, :);&#xA;chk_data = data(trn_data_n+1:trn_data_n+300, :);&#xA;[input_index, elapsed_time]=seqsrch(3, trn_data, chk_data, input_name);&#xA;fprintf('\nElapsed time = %f\n', elapsed_time);&#xA;winH1 = gcf;&#xA;&#xA;%%&#xA;% For input selection, another more computation intensive approach is to do&#xA;% an exhaustive search on all possible combinations of the input&#xA;% candidates. The function that performs exhaustive search is exhsrch,&#xA;% which selects 3 inputs from 10 candidates.  However, exhsrch usually&#xA;% involves a significant amount of computation if all combinations are&#xA;% tried.  For instance, if 3 is selected out of 10, the total number of&#xA;% ANFIS models is C(10, 3) = 120.&#xA;%&#xA;% Fortunately, for dynamical system identification, we do know that the inputs should not come from either of the following two sets of input candidates exclusively:&#xA;%&#xA;% Y = {y(k-1), y(k-2), y(k-3), y(k-4)}&#xA;%&#xA;% U = {u(k-1), u(k-2), u(k-3), u(k-4), u(k-5), u(k-6)}&#xA;%&#xA;% A reasonable guess would be to take two inputs from Y and one from U to&#xA;% form the inputs to ANFIS; the total number of ANFIS models is then&#xA;% C(4,2)*6=36, which is much less.  The above plot shows that the selected&#xA;% inputs are y(k-1), y(k-2) and u(k-3), with a training RMSE of 0.0474 and&#xA;% checking RMSE of 0.0485, which are better than ARX models and ANFIS via&#xA;% sequential forward search.&#xA;&#xA;group1 = [1 2 3 4];	% y(k-1), y(k-2), y(k-3), y(k-4)&#xA;group2 = [1 2 3 4];	% y(k-1), y(k-2), y(k-3), y(k-4)&#xA;group3 = [5 6 7 8 9 10];	% u(k-1) through y(k-6)&#xA;&#xA;anfis_n = 6*length(group3);&#xA;index = zeros(anfis_n, 3);&#xA;trn_error = zeros(anfis_n, 1);&#xA;chk_error = zeros(anfis_n, 1);&#xA;% ======= Training options &#xA;mf_n = 2;&#xA;mf_type = 'gbellmf';&#xA;epoch_n = 1;&#xA;ss = 0.1;&#xA;ss_dec_rate = 0.5;&#xA;ss_inc_rate = 1.5;&#xA;% ====== Train ANFIS with different input variables&#xA;fprintf('\nTrain %d ANFIS models, each with 3 inputs selected from 10 candidates...\n\n',...&#xA;    anfis_n);&#xA;model = 1;&#xA;for i=1:length(group1),&#xA;    for j=i+1:length(group2),&#xA;        for k=1:length(group3),&#xA;            in1 = deblank(input_name(group1(i), :));&#xA;            in2 = deblank(input_name(group2(j), :));&#xA;            in3 = deblank(input_name(group3(k), :));&#xA;            index(model, :) = [group1(i) group2(j) group3(k)];&#xA;            trn_data = data(1:trn_data_n, [group1(i) group2(j) group3(k) size(data,2)]);&#xA;            chk_data = data(trn_data_n+1:trn_data_n+300, [group1(i) group2(j) group3(k) size(data,2)]);&#xA;            in_fismat = genfis1(trn_data, mf_n, mf_type);&#xA;            [trn_out_fismat t_err step_size chk_out_fismat c_err] = ...&#xA;                anfis(trn_data, in_fismat, ...&#xA;                [epoch_n nan ss ss_dec_rate ss_inc_rate], ...&#xA;                [0 0 0 0], chk_data, 1);&#xA;            trn_error(model) = min(t_err);&#xA;            chk_error(model) = min(c_err);&#xA;            fprintf('ANFIS model = %d: %s %s %s', model, in1, in2, in3);&#xA;            fprintf(' --&gt; trn=%.4f,', trn_error(model));&#xA;            fprintf(' chk=%.4f', chk_error(model));&#xA;            fprintf('\n');&#xA;            model = model+1;&#xA;        end&#xA;    end&#xA;end&#xA;&#xA;% ====== Reordering according to training error&#xA;[a b] = sort(trn_error);&#xA;b = flipud(b);		% List according to decreasing trn error&#xA;trn_error = trn_error(b);&#xA;chk_error = chk_error(b);&#xA;index = index(b, :);&#xA;&#xA;% ====== Display training and checking errors&#xA;x = (1:anfis_n)';&#xA;subplot(2,1,1);&#xA;plot(x, trn_error, '-', x, chk_error, '-', ...&#xA;    x, trn_error, 'o', x, chk_error, '*');&#xA;tmp = x(:, ones(1, 3))';&#xA;X = tmp(:);&#xA;tmp = [zeros(anfis_n, 1) max(trn_error, chk_error) nan*ones(anfis_n, 1)]';&#xA;Y = tmp(:);&#xA;hold on; &#xA;plot(X, Y, 'g'); &#xA;hold off;&#xA;axis([1 anfis_n -inf inf]);&#xA;set(gca, 'xticklabel', []);&#xA;&#xA;% ====== Add text of input variables&#xA;for k = 1:anfis_n,&#xA;    text(x(k), 0, ...&#xA;        [input_name(index(k,1), :) ' ' ...&#xA;            input_name(index(k,2), :) ' ' ...&#xA;            input_name(index(k,3), :)]);&#xA;end&#xA;h = findobj(gcf, 'type', 'text');&#xA;set(h, 'rot', 90, 'fontsize', 11, 'hori', 'right');&#xA;drawnow&#xA;&#xA;% ====== Generate input_index for bjtrain.m&#xA;[a b] = min(trn_error);&#xA;input_index = index(b,:);&#xA;title('Training (Circles) and Checking (Asterisks) Errors');&#xA;ylabel('RMSE');&#xA;&#xA;%%&#xA;% The popped window shows ANFIS predictions on both training and checking&#xA;% data sets.  Obviously the performance is better than those of the ARX&#xA;% model.&#xA;&#xA;if ishandle(winH1), delete(winH1); end&#xA;&#xA;ss = 0.01;&#xA;ss_dec_rate = 0.5;&#xA;ss_inc_rate = 1.5;&#xA;&#xA;trn_data = data(1:trn_data_n, [input_index, size(data,2)]);&#xA;chk_data = data(trn_data_n+1:600, [input_index, size(data,2)]);&#xA;&#xA;% generate FIS matrix&#xA;in_fismat = genfis1(trn_data);&#xA;&#xA;[trn_out_fismat trn_error step_size chk_out_fismat chk_error] = ...&#xA;    anfis(trn_data, in_fismat, [1 nan ss ss_dec_rate ss_inc_rate], ...&#xA;    nan, chk_data, 1);&#xA;&#xA;subplot(2,1,1);&#xA;index = 1:trn_data_n;&#xA;plot(index, y(index), index, yp(index), '.');&#xA;rmse = norm(y(index)-yp(index))/sqrt(length(index));&#xA;title(['(a) Training Data (Solid Line) and ARX Prediction (Dots) with RMSE = ' num2str(rmse)]);&#xA;disp(['[na nb d] = ' num2str(nn)]);&#xA;xlabel('Time Steps');&#xA;subplot(2,1,2);&#xA;index = (trn_data_n+1):(total_data_n);&#xA;plot(index, y(index), index, yp(index), '.');&#xA;rmse = norm(y(index)-yp(index))/sqrt(length(index));&#xA;title(['(b) Checking Data (Solid Line) and ARX Prediction (Dots) with RMSE = ' num2str(rmse)]);&#xA;xlabel('Time Steps');&#xA;&#xA;%%&#xA;y_hat = evalfis(data(1:600,input_index), chk_out_fismat);&#xA;&#xA;subplot(2,1,1);&#xA;index = 1:trn_data_n;&#xA;plot(index, data(index, size(data,2)), '-', ...&#xA;    index, y_hat(index), '.');&#xA;rmse = norm(y_hat(index)-data(index,size(data,2)))/sqrt(length(index));&#xA;title(['Training Data (Solid Line) and ANFIS Prediction (Dots) with RMSE = ' num2str(rmse)]);&#xA;xlabel('Time Index'); ylabel('');&#xA;&#xA;subplot(2,1,2);&#xA;index = trn_data_n+1:600;&#xA;plot(index, data(index, size(data,2)), '-', index, y_hat(index), '.');&#xA;rmse = norm(y_hat(index)-data(index,size(data,2)))/sqrt(length(index));&#xA;title(['Checking Data (Solid Line) and ANFIS Prediction (Dots) with RMSE = ' num2str(rmse)]);&#xA;xlabel('Time Index'); ylabel('');&#xA;&#xA;%%&#xA;% The above table is a comparison among various modeling approaches. The&#xA;% ARX modeling spends the least amount of time to reach the worse&#xA;% precision, which the ANFIS modeling via exhaustive search takes the&#xA;% largest amount of time to reach the best percision.  In other words, if&#xA;% fast modeling is the goal, then ARX is the right choice.  But if&#xA;% precision is the utmost concern, then we can go for ANFIS that is&#xA;% designed for nonlinear modeling and higher precision.&#xA;&#xA;subplot(1,1,1)&#xA;a=imread('drytable.jpg', 'jpg');&#xA;image(a); &#xA;axis image;&#xA;axis off;"></originalCode>