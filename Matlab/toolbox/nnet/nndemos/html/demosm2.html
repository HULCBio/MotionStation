<!--
This HTML is auto-generated from an m-file.
Your changes will be overwritten.
--><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:x-large">A Two-dimensional Self-organizing Map</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">As in DEMOSM1, this self-organizing map will learn to represent different
regions of the input space where input vectors occur.  In this demo, however,
the neurons will arrange themselves in a two-dimensional grid, rather than a
line.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Copyright 1992-2002 The MathWorks, Inc.
$Revision: 1.18 $  $Date: 2002/03/29 19:36:02 $
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">We would like to classify 1000 two-element vectors occuring in a rectangular
shaped vector space.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">P = rands(2,1000);
plot(P(1,:),P(2,:),<span style="color:#B20000">'+r'</span>)</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="demosm2_img02.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">We will use a 5 by 6 layer of neurons to classify the vectors above. We would
like each neuron to respond to a different region of the rectangle, and
neighboring neurons to respond to adjacent regions.  We create a layer of 30
neurons spread out in a 5 by 6 grid:
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">net = newsom([0 1; 0 1],[5 6]);</pre><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">We can visualize the network we have just created with PLOTSOM.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Each neuron is represented by a red dot at the location of its two weights.
Initially all the neurons have the same weights in the middle of the vectors,
so only one dot appears.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">plotsom(net.iw{1,1},net.layers{1}.distances)</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="demosm2_img04.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Now we train the map on the 1000 vectors for 1 epoch and replot the network
weights.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">After training, note that the layer of neurons has begun to self-organize so
that each neuron now classifies a different region of the input space, and
adjacent (connected) neurons respond to adjacent regions.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">net.trainParam.epochs = 1;
net = train(net,P);
plotsom(net.iw{1,1},net.layers{1}.distances)</pre><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:gray; font-style:italic;">TRAINR, Epoch 0/1
TRAINR, Epoch 1/1
TRAINR, Maximum epoch reached.

</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="demosm2_img05.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">We can now use SIM to classify vectors by giving them to the network and
seeing which neuron responds.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">The neuron indicated by "a" responded with a "1", so p belongs to that class.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">p = [0.5;0.3];
a = sim(net,p)</pre><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:gray; font-style:italic;">
a =

  (19,1)        1

</pre><originalCode xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" code="%% A Two-dimensional Self-organizing Map&#xA;% As in DEMOSM1, this self-organizing map will learn to represent different&#xA;% regions of the input space where input vectors occur.  In this demo, however,&#xA;% the neurons will arrange themselves in a two-dimensional grid, rather than a&#xA;% line.&#xA;%&#xA;% Copyright 1992-2002 The MathWorks, Inc. &#xA;% $Revision: 1.18 $  $Date: 2002/03/29 19:36:02 $&#xA;&#xA;%%&#xA;% We would like to classify 1000 two-element vectors occuring in a rectangular&#xA;% shaped vector space.&#xA;&#xA;P = rands(2,1000);&#xA;plot(P(1,:),P(2,:),'+r')&#xA;&#xA;%%&#xA;% We will use a 5 by 6 layer of neurons to classify the vectors above. We would&#xA;% like each neuron to respond to a different region of the rectangle, and&#xA;% neighboring neurons to respond to adjacent regions.  We create a layer of 30&#xA;% neurons spread out in a 5 by 6 grid:&#xA;&#xA;net = newsom([0 1; 0 1],[5 6]);&#xA;&#xA;%%&#xA;% We can visualize the network we have just created with PLOTSOM.&#xA;% &#xA;% Each neuron is represented by a red dot at the location of its two weights.&#xA;% Initially all the neurons have the same weights in the middle of the vectors,&#xA;% so only one dot appears.&#xA;&#xA;plotsom(net.iw{1,1},net.layers{1}.distances)&#xA;&#xA;%%&#xA;% Now we train the map on the 1000 vectors for 1 epoch and replot the network&#xA;% weights.&#xA;% &#xA;% After training, note that the layer of neurons has begun to self-organize so&#xA;% that each neuron now classifies a different region of the input space, and&#xA;% adjacent (connected) neurons respond to adjacent regions.&#xA;&#xA;net.trainParam.epochs = 1;&#xA;net = train(net,P);&#xA;plotsom(net.iw{1,1},net.layers{1}.distances)&#xA;&#xA;%%&#xA;% We can now use SIM to classify vectors by giving them to the network and&#xA;% seeing which neuron responds.&#xA;% &#xA;% The neuron indicated by &#34;a&#34; responded with a &#34;1&#34;, so p belongs to that class.&#xA;&#xA;p = [0.5;0.3];&#xA;a = sim(net,p)&#xA;"></originalCode>