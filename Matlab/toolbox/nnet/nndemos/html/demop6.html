<!--
This HTML is auto-generated from an m-file.
Your changes will be overwritten.
--><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:x-large">Linearly Non-separable Vectors</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">A 2-input hard limit neuron fails to properly classify 5 input vectors because
they are linearly non-separable.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Copyright 1992-2002 The MathWorks, Inc.
$Revision: 1.15 $  $Date: 2002/03/29 19:36:08 $
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Each of the five column vectors in P defines a 2-element input vectors, and a
row vector T defines the vector's target categories.  Plot these vectors with
PLOTPV.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">P = [ -0.5 -0.5 +0.3 -0.1 -0.8; <span style="color:blue">...</span>
      -0.5 +0.5 -0.5 +1.0 +0.0 ];
T = [1 1 0 0 0];
plotpv(P,T);</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="demop6_img02.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">The perceptron must properly classify the input vectors in P into the
categories defined by T.  Because the two kinds of input vectors cannot be
separated by a straight line, the perceptron will not be able to do it. NEWP
creates a perceptron.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">net = newp([-40 1;-1 50],1);</pre><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Add the the neuron's initial attempt at classification to the plot.  The
initial weights are set to zero, so any input gives the same output and the
classification line does not even appear on the plot.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">hold on
plotpv(P,T);
linehandle=plotpc(net.IW{1},net.b{1});</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="demop6_img04.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">ADAPT returns a new network object that performs as a better classifier, the
network outputs, and the error.  This loop allows the network to adapt for 3
passes, plots the classification line, and stops after 25 iterations.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">net.adaptParam.passes = 3;
linehandle=plotpc(net.IW{1},net.b{1});
<span style="color:blue">for</span> a = 1:25
   [net,Y,E] = adapt(net,P,T);
   linehandle = plotpc(net.IW{1},net.b{1},linehandle);  drawnow;
<span style="color:blue">end</span>;</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="demop6_img05.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Note that zero error was never obtained.  Despite training, the perceptron has
not become an acceptable classifier.  Only being able to classify linearly
separable data is the fundamental limitation of perceptrons.
</p><originalCode xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" code="%% Linearly Non-separable Vectors&#xA;% A 2-input hard limit neuron fails to properly classify 5 input vectors because&#xA;% they are linearly non-separable.&#xA;%&#xA;% Copyright 1992-2002 The MathWorks, Inc. &#xA;% $Revision: 1.15 $  $Date: 2002/03/29 19:36:08 $&#xA;&#xA;%%&#xA;% Each of the five column vectors in P defines a 2-element input vectors, and a&#xA;% row vector T defines the vector's target categories.  Plot these vectors with&#xA;% PLOTPV.&#xA;&#xA;P = [ -0.5 -0.5 +0.3 -0.1 -0.8; ...&#xA;      -0.5 +0.5 -0.5 +1.0 +0.0 ];&#xA;T = [1 1 0 0 0];&#xA;plotpv(P,T);&#xA;&#xA;%%&#xA;% The perceptron must properly classify the input vectors in P into the&#xA;% categories defined by T.  Because the two kinds of input vectors cannot be&#xA;% separated by a straight line, the perceptron will not be able to do it. NEWP&#xA;% creates a perceptron.&#xA;&#xA;net = newp([-40 1;-1 50],1);&#xA;&#xA;%%&#xA;% Add the the neuron's initial attempt at classification to the plot.  The&#xA;% initial weights are set to zero, so any input gives the same output and the&#xA;% classification line does not even appear on the plot.&#xA;&#xA;hold on&#xA;plotpv(P,T);&#xA;linehandle=plotpc(net.IW{1},net.b{1});&#xA;&#xA;%%&#xA;% ADAPT returns a new network object that performs as a better classifier, the&#xA;% network outputs, and the error.  This loop allows the network to adapt for 3&#xA;% passes, plots the classification line, and stops after 25 iterations.&#xA;&#xA;net.adaptParam.passes = 3;&#xA;linehandle=plotpc(net.IW{1},net.b{1});&#xA;for a = 1:25&#xA;   [net,Y,E] = adapt(net,P,T);&#xA;   linehandle = plotpc(net.IW{1},net.b{1},linehandle);  drawnow;&#xA;end;&#xA;&#xA;%%&#xA;% Note that zero error was never obtained.  Despite training, the perceptron has&#xA;% not become an acceptable classifier.  Only being able to classify linearly&#xA;% separable data is the fundamental limitation of perceptrons.&#xA;"></originalCode>