<!--
This HTML is auto-generated from an m-file.
Your changes will be overwritten.
--><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:x-large">Radial Basis Underlapping Neurons</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">A radial basis network is trained to respond to specific inputs with target
outputs.  However, because the spread of the radial basis neurons is too low,
the network requires many neurons.
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Copyright 1992-2002 The MathWorks, Inc.
$Revision: 1.14 $  $Date: 2002/03/29 19:36:05 $
</p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">Define 21 inputs P and associated targets T.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">P = -1:.1:1;
T = [-.9602 -.5770 -.0729  .3771  .6405  .6600  .4609 <span style="color:blue">...</span>
      .1336 -.2013 -.4344 -.5000 -.3930 -.1647  .0988 <span style="color:blue">...</span>
      .3072  .3960  .3449  .1816 -.0312 -.2189 -.3201];
plot(P,T,<span style="color:#B20000">'+'</span>);
title(<span style="color:#B20000">'Training Vectors'</span>);
xlabel(<span style="color:#B20000">'Input Vector P'</span>);
ylabel(<span style="color:#B20000">'Target Vector T'</span>);</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="demorb3_img02.gif"><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">The function NEWRB quickly creates a radial basis network which approximates
the function defined by P and T.  In addition to the training set and targets,
NEWRB takes two arguments, the sum-squared error goal and the spread constant.
The spread of the radial basis neurons B is set to a very small number.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">eg = 0.02; <span style="color:green">% sum-squared error goal</span>
sc = .01;  <span style="color:green">% spread constant</span>
net = newrb(P,T,eg,sc);</pre><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:gray; font-style:italic;">NEWRB, neurons = 0, SSE = 2.758
</pre><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="color:#990000; font-weight:bold; font-size:medium; page-break-before: auto;"><a name=""></a></p><p xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">To check that the network fits the function in a smooth way, define another
set of test input vectors and simulate the network with these new inputs.  Plot
the results on the same graph as the training set.  The test vectors reveal
that the function has been overfit!  The network could have done better with a
higher spread constant.
</p><pre xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" style="position: relative; left:30px">X=-1:.01:1;
Y=sim(net,X);
hold on;
plot(X,Y);
hold off;</pre><img xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" src="demorb3_img04.gif"><originalCode xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd" code="%% Radial Basis Underlapping Neurons&#xA;% A radial basis network is trained to respond to specific inputs with target&#xA;% outputs.  However, because the spread of the radial basis neurons is too low,&#xA;% the network requires many neurons.&#xA;% &#xA;% Copyright 1992-2002 The MathWorks, Inc.&#xA;% $Revision: 1.14 $  $Date: 2002/03/29 19:36:05 $&#xA;&#xA;%%&#xA;% Define 21 inputs P and associated targets T.&#xA;&#xA;P = -1:.1:1;&#xA;T = [-.9602 -.5770 -.0729  .3771  .6405  .6600  .4609 ...&#xA;      .1336 -.2013 -.4344 -.5000 -.3930 -.1647  .0988 ...&#xA;      .3072  .3960  .3449  .1816 -.0312 -.2189 -.3201];&#xA;plot(P,T,'+');&#xA;title('Training Vectors');&#xA;xlabel('Input Vector P');&#xA;ylabel('Target Vector T');&#xA;&#xA;&#xA;%%&#xA;% The function NEWRB quickly creates a radial basis network which approximates&#xA;% the function defined by P and T.  In addition to the training set and targets,&#xA;% NEWRB takes two arguments, the sum-squared error goal and the spread constant.&#xA;% The spread of the radial basis neurons B is set to a very small number.&#xA;&#xA;eg = 0.02; % sum-squared error goal&#xA;sc = .01;  % spread constant&#xA;net = newrb(P,T,eg,sc);&#xA;&#xA;%%&#xA;% To check that the network fits the function in a smooth way, define another&#xA;% set of test input vectors and simulate the network with these new inputs.  Plot&#xA;% the results on the same graph as the training set.  The test vectors reveal&#xA;% that the function has been overfit!  The network could have done better with a&#xA;% higher spread constant.&#xA;&#xA;X=-1:.01:1;&#xA;Y=sim(net,X);&#xA;hold on;&#xA;plot(X,Y);&#xA;hold off;&#xA;"></originalCode>