\subsection{newff}
\textit{newff} is the short form for \textit{\textbf{new f}eed \textbf{f}orward network}. This command creates a feed-forward backpropagation network structure.\\

\noindent \textbf{\textcolor{brown}{Syntax:}}\\

\noindent net = newff(Rx2,[S1 S2 ... SN],\{TF1 TF2 ... TFN\},BTF,BLF,PF)\\

\noindent \textbf{\textcolor{brown}{Description:}}\\

\noindent Rx2: R x 2 matrix of min and max values for R input elements\\ 
\noindent Si: Size of ith layer, for N layers\\ 
\noindent TFi: Transfer function of ith layer, default = "tansig"\\
\noindent BTF: Backpropagation network training function, default = "trainlm" \\
\noindent BLF: Backpropagation weight/bias learning function, NOT USED, is only for MATLAB(TM) compatibility\\
\noindent PF: Performance function, default = "mse"\\

\noindent \textbf{\textcolor{brown}{Examples:}}\\

\noindent net = newff(Rx2,[2 1])\\
\noindent net = newff(Rx2,[2 1],\{"tansig","purelin"\});\\
\noindent net = newff(Rx2,[2 1],\{"tansig","purelin"\},"trainlm");\\
\noindent net = newff(Rx2,[2 1],\{"tansig","purelin"\},"trainlm","notUsed","mse");\\

\noindent \textbf{\textcolor{brown}{Comments:}}\\
In this version, you can have as much output neurons as you want. The same with the number of hidden layers. This means you can have one input layer, unrestricted number of hidden layers and one output layer. That's it.\\


